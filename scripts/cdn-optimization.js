#!/usr/bin/env node\n\n/**\n * CDN Optimization Script for MariaIntelligence\n * Handles asset optimization, compression, and CDN preparation\n */\n\nconst fs = require('fs');\nconst path = require('path');\nconst crypto = require('crypto');\nconst { execSync } = require('child_process');\nconst sharp = require('sharp').default || require('sharp'); // Handle both import styles\nconst performanceConfig = require('../config/performance.config.js');\n\nclass CDNOptimizer {\n  constructor() {\n    this.assetsDir = path.join(process.cwd(), 'client', 'public');\n    this.distDir = path.join(process.cwd(), 'client', 'dist');\n    this.optimizedDir = path.join(process.cwd(), 'cdn-assets');\n    this.manifestFile = path.join(this.optimizedDir, 'manifest.json');\n    this.manifest = {};\n    \n    console.log('üöÄ CDN Optimizer initialized');\n    console.log(`üìÅ Assets directory: ${this.assetsDir}`);\n    console.log(`üìÅ Output directory: ${this.optimizedDir}`);\n  }\n  \n  /**\n   * Run complete CDN optimization\n   */\n  async optimize() {\n    console.log('üîÑ Starting CDN optimization...');\n    \n    try {\n      // Create output directory\n      await this.createOutputDirectory();\n      \n      // Optimize images\n      await this.optimizeImages();\n      \n      // Optimize CSS and JS\n      await this.optimizeAssets();\n      \n      // Generate asset manifest\n      await this.generateManifest();\n      \n      // Create compression variants\n      await this.createCompressionVariants();\n      \n      // Generate CDN upload script\n      await this.generateUploadScript();\n      \n      console.log('‚úÖ CDN optimization completed successfully!');\n      console.log(`üìä Optimized ${Object.keys(this.manifest).length} assets`);\n      \n    } catch (error) {\n      console.error('‚ùå CDN optimization failed:', error.message);\n      process.exit(1);\n    }\n  }\n  \n  /**\n   * Create output directory structure\n   */\n  async createOutputDirectory() {\n    console.log('üìÅ Creating output directory structure...');\n    \n    const dirs = [\n      this.optimizedDir,\n      path.join(this.optimizedDir, 'images'),\n      path.join(this.optimizedDir, 'css'),\n      path.join(this.optimizedDir, 'js'),\n      path.join(this.optimizedDir, 'fonts'),\n      path.join(this.optimizedDir, 'compressed')\n    ];\n    \n    dirs.forEach(dir => {\n      if (!fs.existsSync(dir)) {\n        fs.mkdirSync(dir, { recursive: true });\n      }\n    });\n  }\n  \n  /**\n   * Optimize images with multiple formats and sizes\n   */\n  async optimizeImages() {\n    console.log('üñºÔ∏è  Optimizing images...');\n    \n    const imageExtensions = performanceConfig.cdn.staticAssets.images;\n    const breakpoints = performanceConfig.images.breakpoints;\n    const quality = performanceConfig.images.quality;\n    \n    const findImages = (dir) => {\n      const files = [];\n      if (!fs.existsSync(dir)) return files;\n      \n      const items = fs.readdirSync(dir, { withFileTypes: true });\n      for (const item of items) {\n        const fullPath = path.join(dir, item.name);\n        if (item.isDirectory()) {\n          files.push(...findImages(fullPath));\n        } else if (imageExtensions.some(ext => item.name.toLowerCase().endsWith(ext))) {\n          files.push(fullPath);\n        }\n      }\n      return files;\n    };\n    \n    const imageFiles = [...findImages(this.assetsDir), ...findImages(this.distDir)];\n    console.log(`üì∏ Found ${imageFiles.length} images to optimize`);\n    \n    for (const imagePath of imageFiles) {\n      try {\n        await this.optimizeImage(imagePath, quality, breakpoints);\n      } catch (error) {\n        console.warn(`‚ö†Ô∏è  Failed to optimize ${imagePath}:`, error.message);\n      }\n    }\n  }\n  \n  /**\n   * Optimize single image with multiple formats and sizes\n   */\n  async optimizeImage(imagePath, quality, breakpoints) {\n    const relativePath = path.relative(process.cwd(), imagePath);\n    const fileName = path.basename(imagePath, path.extname(imagePath));\n    const originalExt = path.extname(imagePath).toLowerCase();\n    \n    console.log(`  üì∏ Processing: ${relativePath}`);\n    \n    const image = sharp(imagePath);\n    const metadata = await image.metadata();\n    \n    // Generate hash for cache busting\n    const fileContent = fs.readFileSync(imagePath);\n    const hash = crypto.createHash('md5').update(fileContent).digest('hex').substring(0, 8);\n    \n    const formats = ['webp', 'avif', 'jpg'];\n    const sizes = breakpoints.filter(size => size <= metadata.width);\n    \n    // Add original size if not in breakpoints\n    if (!sizes.includes(metadata.width)) {\n      sizes.push(metadata.width);\n    }\n    \n    const optimizedFiles = [];\n    \n    for (const format of formats) {\n      for (const size of sizes) {\n        const outputFileName = `${fileName}-${size}w-${hash}.${format}`;\n        const outputPath = path.join(this.optimizedDir, 'images', outputFileName);\n        \n        try {\n          await image\n            .clone()\n            .resize(size, null, {\n              withoutEnlargement: true,\n              fastShrinkOnLoad: false\n            })\n            [format]({\n              quality: format === 'jpg' ? quality : undefined,\n              effort: format === 'avif' ? 4 : undefined\n            })\n            .toFile(outputPath);\n            \n          const stats = fs.statSync(outputPath);\n          optimizedFiles.push({\n            format,\n            size,\n            filename: outputFileName,\n            path: outputPath,\n            bytes: stats.size\n          });\n        } catch (error) {\n          console.warn(`    ‚ö†Ô∏è  Failed to create ${format} at ${size}w:`, error.message);\n        }\n      }\n    }\n    \n    // Add to manifest\n    this.manifest[relativePath] = {\n      original: {\n        path: relativePath,\n        size: metadata.width,\n        bytes: fs.statSync(imagePath).size,\n        format: originalExt.substring(1)\n      },\n      optimized: optimizedFiles,\n      hash\n    };\n    \n    console.log(`    ‚úÖ Generated ${optimizedFiles.length} variants`);\n  }\n  \n  /**\n   * Optimize CSS and JavaScript assets\n   */\n  async optimizeAssets() {\n    console.log('üìù Optimizing CSS and JavaScript...');\n    \n    // Find CSS and JS files in dist directory\n    const findAssets = (dir, extensions) => {\n      const files = [];\n      if (!fs.existsSync(dir)) return files;\n      \n      const items = fs.readdirSync(dir, { withFileTypes: true });\n      for (const item of items) {\n        const fullPath = path.join(dir, item.name);\n        if (item.isDirectory()) {\n          files.push(...findAssets(fullPath, extensions));\n        } else if (extensions.some(ext => item.name.endsWith(ext))) {\n          files.push(fullPath);\n        }\n      }\n      return files;\n    };\n    \n    const cssFiles = findAssets(this.distDir, ['.css']);\n    const jsFiles = findAssets(this.distDir, ['.js']);\n    \n    console.log(`üìù Found ${cssFiles.length} CSS files and ${jsFiles.length} JS files`);\n    \n    // Process CSS files\n    for (const cssFile of cssFiles) {\n      await this.optimizeCSSFile(cssFile);\n    }\n    \n    // Process JS files\n    for (const jsFile of jsFiles) {\n      await this.optimizeJSFile(jsFile);\n    }\n  }\n  \n  /**\n   * Optimize single CSS file\n   */\n  async optimizeCSSFile(cssPath) {\n    const relativePath = path.relative(process.cwd(), cssPath);\n    const fileName = path.basename(cssPath);\n    const content = fs.readFileSync(cssPath, 'utf8');\n    \n    // Generate hash\n    const hash = crypto.createHash('md5').update(content).digest('hex').substring(0, 8);\n    const hashedFileName = fileName.replace('.css', `-${hash}.css`);\n    \n    const outputPath = path.join(this.optimizedDir, 'css', hashedFileName);\n    \n    // Simple CSS minification (remove comments and extra whitespace)\n    let minified = content\n      .replace(/\\/\\*[\\s\\S]*?\\*\\//g, '') // Remove comments\n      .replace(/\\s+/g, ' ') // Collapse whitespace\n      .replace(/;\\s*}/g, '}') // Remove unnecessary semicolons\n      .trim();\n    \n    fs.writeFileSync(outputPath, minified);\n    \n    const originalSize = fs.statSync(cssPath).size;\n    const optimizedSize = fs.statSync(outputPath).size;\n    const savings = ((originalSize - optimizedSize) / originalSize * 100).toFixed(1);\n    \n    this.manifest[relativePath] = {\n      original: {\n        path: relativePath,\n        bytes: originalSize\n      },\n      optimized: {\n        filename: hashedFileName,\n        path: outputPath,\n        bytes: optimizedSize,\n        savings: `${savings}%`\n      },\n      hash,\n      type: 'css'\n    };\n    \n    console.log(`  üìù CSS: ${fileName} -> ${hashedFileName} (${savings}% smaller)`);\n  }\n  \n  /**\n   * Optimize single JavaScript file\n   */\n  async optimizeJSFile(jsPath) {\n    const relativePath = path.relative(process.cwd(), jsPath);\n    const fileName = path.basename(jsPath);\n    const content = fs.readFileSync(jsPath, 'utf8');\n    \n    // Generate hash\n    const hash = crypto.createHash('md5').update(content).digest('hex').substring(0, 8);\n    const hashedFileName = fileName.replace('.js', `-${hash}.js`);\n    \n    const outputPath = path.join(this.optimizedDir, 'js', hashedFileName);\n    \n    // Copy file (minification would be handled by build process)\n    fs.writeFileSync(outputPath, content);\n    \n    const originalSize = fs.statSync(jsPath).size;\n    const optimizedSize = fs.statSync(outputPath).size;\n    \n    this.manifest[relativePath] = {\n      original: {\n        path: relativePath,\n        bytes: originalSize\n      },\n      optimized: {\n        filename: hashedFileName,\n        path: outputPath,\n        bytes: optimizedSize\n      },\n      hash,\n      type: 'js'\n    };\n    \n    console.log(`  üìù JS: ${fileName} -> ${hashedFileName}`);\n  }\n  \n  /**\n   * Generate asset manifest file\n   */\n  async generateManifest() {\n    console.log('üìã Generating asset manifest...');\n    \n    const manifest = {\n      generated: new Date().toISOString(),\n      version: '1.0',\n      cdnBaseUrl: performanceConfig.cdn.baseUrl,\n      assets: this.manifest,\n      summary: {\n        totalAssets: Object.keys(this.manifest).length,\n        totalSizeOriginal: Object.values(this.manifest).reduce((sum, asset) => sum + asset.original.bytes, 0),\n        totalSizeOptimized: Object.values(this.manifest).reduce((sum, asset) => {\n          return sum + (asset.optimized.bytes || asset.optimized.reduce((s, o) => s + o.bytes, 0));\n        }, 0)\n      }\n    };\n    \n    // Calculate total savings\n    manifest.summary.totalSavings = manifest.summary.totalSizeOriginal - manifest.summary.totalSizeOptimized;\n    manifest.summary.savingsPercentage = (\n      (manifest.summary.totalSavings / manifest.summary.totalSizeOriginal) * 100\n    ).toFixed(1);\n    \n    fs.writeFileSync(this.manifestFile, JSON.stringify(manifest, null, 2));\n    \n    console.log(`üìä Manifest generated: ${Object.keys(this.manifest).length} assets`);\n    console.log(`üíæ Original size: ${(manifest.summary.totalSizeOriginal / 1024 / 1024).toFixed(2)} MB`);\n    console.log(`üíæ Optimized size: ${(manifest.summary.totalSizeOptimized / 1024 / 1024).toFixed(2)} MB`);\n    console.log(`üìâ Savings: ${manifest.summary.savingsPercentage}%`);\n  }\n  \n  /**\n   * Create compressed variants (gzip, brotli)\n   */\n  async createCompressionVariants() {\n    console.log('üóúÔ∏è  Creating compression variants...');\n    \n    const zlib = require('zlib');\n    const { promisify } = require('util');\n    const gzip = promisify(zlib.gzip);\n    const brotliCompress = promisify(zlib.brotliCompress);\n    \n    const compressibleFiles = [];\n    \n    // Find compressible files\n    const findCompressibleFiles = (dir) => {\n      const files = [];\n      if (!fs.existsSync(dir)) return files;\n      \n      const items = fs.readdirSync(dir, { withFileTypes: true });\n      for (const item of items) {\n        const fullPath = path.join(dir, item.name);\n        if (item.isDirectory() && item.name !== 'compressed') {\n          files.push(...findCompressibleFiles(fullPath));\n        } else if (item.isFile()) {\n          const ext = path.extname(item.name).toLowerCase();\n          if (['.css', '.js', '.html', '.json', '.xml', '.svg'].includes(ext)) {\n            files.push(fullPath);\n          }\n        }\n      }\n      return files;\n    };\n    \n    compressibleFiles.push(...findCompressibleFiles(this.optimizedDir));\n    \n    console.log(`üóúÔ∏è  Found ${compressibleFiles.length} compressible files`);\n    \n    for (const filePath of compressibleFiles) {\n      try {\n        const content = fs.readFileSync(filePath);\n        const fileName = path.basename(filePath);\n        \n        // Create gzip version\n        const gzipContent = await gzip(content);\n        const gzipPath = path.join(this.optimizedDir, 'compressed', fileName + '.gz');\n        fs.writeFileSync(gzipPath, gzipContent);\n        \n        // Create brotli version\n        const brotliContent = await brotliCompress(content);\n        const brotliPath = path.join(this.optimizedDir, 'compressed', fileName + '.br');\n        fs.writeFileSync(brotliPath, brotliContent);\n        \n        const originalSize = content.length;\n        const gzipSize = gzipContent.length;\n        const brotliSize = brotliContent.length;\n        \n        console.log(`    üóúÔ∏è  ${fileName}: ${originalSize}b -> gzip: ${gzipSize}b (${((originalSize - gzipSize) / originalSize * 100).toFixed(1)}%) -> brotli: ${brotliSize}b (${((originalSize - brotliSize) / originalSize * 100).toFixed(1)}%)`);\n        \n      } catch (error) {\n        console.warn(`‚ö†Ô∏è  Failed to compress ${filePath}:`, error.message);\n      }\n    }\n  }\n  \n  /**\n   * Generate CDN upload script\n   */\n  async generateUploadScript() {\n    console.log('üì§ Generating CDN upload script...');\n    \n    const uploadScript = `#!/bin/bash\n\n# CDN Upload Script for MariaIntelligence\n# Generated: ${new Date().toISOString()}\n\nset -e\n\necho \"üì§ Uploading optimized assets to CDN...\"\n\n# Configuration\nCDN_BUCKET=\"your-cdn-bucket\"\nCDN_REGION=\"your-region\"\nASSETS_DIR=\"${this.optimizedDir}\"\nCDN_BASE_URL=\"${performanceConfig.cdn.baseUrl}\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\nprint_status() {\n    echo -e \"\\${GREEN}[INFO]\\${NC} $1\"\n}\n\nprint_warning() {\n    echo -e \"\\${YELLOW}[WARNING]\\${NC} $1\"\n}\n\nprint_error() {\n    echo -e \"\\${RED}[ERROR]\\${NC} $1\"\n}\n\n# Check if AWS CLI is installed\nif ! command -v aws &> /dev/null; then\n    print_error \"AWS CLI is required but not installed\"\n    echo \"Install with: curl 'https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip' -o 'awscliv2.zip' && unzip awscliv2.zip && sudo ./aws/install\"\n    exit 1\nfi\n\n# Check AWS configuration\nif ! aws sts get-caller-identity &> /dev/null; then\n    print_error \"AWS CLI is not configured\"\n    echo \"Run: aws configure\"\n    exit 1\nfi\n\nprint_status \"Starting CDN upload...\"\n\n# Upload images with proper content types\nprint_status \"Uploading optimized images...\"\naws s3 sync \"\\$ASSETS_DIR/images\" \"s3://\\$CDN_BUCKET/assets/images\" \\\\\n    --delete \\\\\n    --cache-control \"public, max-age=31536000, immutable\" \\\\\n    --content-encoding \"identity\"\n\n# Upload CSS files\nprint_status \"Uploading CSS files...\"\naws s3 sync \"\\$ASSETS_DIR/css\" \"s3://\\$CDN_BUCKET/assets/css\" \\\\\n    --delete \\\\\n    --cache-control \"public, max-age=86400\" \\\\\n    --content-type \"text/css\"\n\n# Upload JS files\nprint_status \"Uploading JavaScript files...\"\naws s3 sync \"\\$ASSETS_DIR/js\" \"s3://\\$CDN_BUCKET/assets/js\" \\\\\n    --delete \\\\\n    --cache-control \"public, max-age=86400\" \\\\\n    --content-type \"application/javascript\"\n\n# Upload compressed variants\nprint_status \"Uploading compressed variants...\"\naws s3 sync \"\\$ASSETS_DIR/compressed\" \"s3://\\$CDN_BUCKET/assets/compressed\" \\\\\n    --delete \\\\\n    --cache-control \"public, max-age=31536000, immutable\"\n\n# Upload manifest\nprint_status \"Uploading asset manifest...\"\naws s3 cp \"\\$ASSETS_DIR/manifest.json\" \"s3://\\$CDN_BUCKET/manifest.json\" \\\\\n    --cache-control \"public, max-age=300\" \\\\\n    --content-type \"application/json\"\n\n# Create CloudFront invalidation (optional)\n# CLOUDFRONT_DISTRIBUTION_ID=\"your-distribution-id\"\n# if [ ! -z \"\\$CLOUDFRONT_DISTRIBUTION_ID\" ]; then\n#     print_status \"Creating CloudFront invalidation...\"\n#     aws cloudfront create-invalidation \\\\\n#         --distribution-id \"\\$CLOUDFRONT_DISTRIBUTION_ID\" \\\\\n#         --paths \"/manifest.json\" \"/assets/*\"\n# fi\n\nprint_status \"‚úÖ CDN upload completed successfully!\"\nprint_status \"Assets available at: \\$CDN_BASE_URL\"\n\n# Display upload summary\necho \"\"\necho \"üìä Upload Summary:\"\necho \"=================\"\necho \"Images: $(find \"\\$ASSETS_DIR/images\" -type f | wc -l) files\"\necho \"CSS: $(find \"\\$ASSETS_DIR/css\" -type f | wc -l) files\"\necho \"JS: $(find \"\\$ASSETS_DIR/js\" -type f | wc -l) files\"\necho \"Compressed: $(find \"\\$ASSETS_DIR/compressed\" -type f | wc -l) files\"\necho \"\"\necho \"üåê CDN Base URL: \\$CDN_BASE_URL\"\necho \"üìã Manifest: \\$CDN_BASE_URL/manifest.json\"\n`;\n    \n    const scriptPath = path.join(this.optimizedDir, 'upload-to-cdn.sh');\n    fs.writeFileSync(scriptPath, uploadScript);\n    \n    // Make script executable\n    try {\n      fs.chmodSync(scriptPath, '755');\n    } catch (error) {\n      console.warn('‚ö†Ô∏è  Could not make upload script executable:', error.message);\n    }\n    \n    console.log(`üì§ Upload script generated: ${scriptPath}`);\n    \n    // Generate instructions\n    const instructions = `# CDN Optimization Instructions\n\n## Upload to CDN\n\n1. Configure AWS CLI:\n   \\`\\`\\`bash\n   aws configure\n   \\`\\`\\`\n\n2. Update the upload script with your CDN details:\n   - Edit \\`${scriptPath}\\`\n   - Set CDN_BUCKET and CDN_REGION\n   - Optional: Set CLOUDFRONT_DISTRIBUTION_ID\n\n3. Run the upload script:\n   \\`\\`\\`bash\n   ./cdn-assets/upload-to-cdn.sh\n   \\`\\`\\`\n\n## Integration\n\nUpdate your application configuration:\n\\`\\`\\`javascript\nconst manifest = require('./cdn-assets/manifest.json');\n\n// Use optimized assets\nfunction getOptimizedAsset(originalPath) {\n  const asset = manifest.assets[originalPath];\n  if (asset && asset.optimized) {\n    return \\`\\${manifest.cdnBaseUrl}/assets/\\${asset.optimized.filename || asset.optimized[0].filename}\\`;\n  }\n  return originalPath; // Fallback\n}\n\\`\\`\\`\n\n## Performance Benefits\n\n- **Image optimization**: Multiple formats (WebP, AVIF, JPEG) and sizes\n- **Asset hashing**: Cache busting with content-based hashes\n- **Compression**: Gzip and Brotli variants for all text assets\n- **CDN delivery**: Global edge locations for fast delivery\n- **Cache headers**: Optimal caching strategies\n\n## Generated Files\n\n- \\`manifest.json\\`: Asset manifest with optimization details\n- \\`images/\\`: Optimized images in multiple formats and sizes\n- \\`css/\\`: Minified and hashed CSS files\n- \\`js/\\`: Hashed JavaScript files\n- \\`compressed/\\`: Gzip and Brotli compressed variants\n- \\`upload-to-cdn.sh\\`: Upload script for your CDN\n`;\n    \n    fs.writeFileSync(path.join(this.optimizedDir, 'README.md'), instructions);\n    console.log(`üìã Instructions generated: ${path.join(this.optimizedDir, 'README.md')}`);\n  }\n}\n\n// Handle command line execution\nif (require.main === module) {\n  const optimizer = new CDNOptimizer();\n  optimizer.optimize().catch(error => {\n    console.error('‚ùå CDN optimization failed:', error);\n    process.exit(1);\n  });\n}\n\nmodule.exports = CDNOptimizer;\n"