/**
 * Servi√ßo para processamento de fala e voz (speech)
 * Utiliza o Gemini 2.5 Pro Experimental para receber e processar
 * entrada de √°udio de usu√°rio e converter para texto
 */

import { GeminiService, GeminiModel } from './gemini.service';

export class SpeechService {
  private static instance: SpeechService;
  private geminiService: GeminiService;
  
  private constructor() {
    this.geminiService = new GeminiService();
  }
  
  /**
   * Obt√©m a inst√¢ncia √∫nica do servi√ßo de fala
   * @returns Inst√¢ncia do servi√ßo
   */
  public static getInstance(): SpeechService {
    if (!SpeechService.instance) {
      SpeechService.instance = new SpeechService();
    }
    return SpeechService.instance;
  }

  /**
   * Processa √°udio e converte para texto
   * @param audioBase64 √Åudio em formato base64
   * @param mimeType Tipo MIME do √°udio (default: audio/webm)
   * @returns Texto transcrito
   */
  async processAudio(audioBase64: string, mimeType: string = 'audio/webm'): Promise<string> {
    // FUNCIONALIDADE TEMPORARIAMENTE DESATIVADA
    console.log('üö´ Funcionalidade de transcri√ß√£o de √°udio temporariamente desativada');
    return "RECURSO_DESATIVADO: A entrada de voz est√° temporariamente indispon√≠vel devido a limita√ß√µes t√©cnicas. Por favor, digite sua mensagem no campo de texto.";
    
    /* C√≥digo original comentado
    try {
      console.log(`Processando √°udio de tipo: ${mimeType}`);
      // Implementar m√©todo alternativo em vez de usar o modelo experimental diretamente
      
      // Verificar se temos acesso ao modelo audioModel
      if (!this.geminiService['audioModel']) {
        console.log('Modelo de √°udio n√£o dispon√≠vel, usando m√©todo alternativo');
        return "Transcri√ß√£o n√£o dispon√≠vel no momento. Por favor, digite seu texto.";
      }
      
      try {
        // Tentar utilizar o modelo experimental para √°udio
        const result = await this.geminiService['audioModel'].generateContent({
          contents: [
            {
              role: 'user',
              parts: [
                { 
                  text: `Escute este √°udio e transcreva exatamente o que est√° sendo dito. 
                  Se ouvir informa√ß√µes sobre reservas, propriedades ou datas, preste aten√ß√£o 
                  especial para capturar esses detalhes com precis√£o.`
                },
                { 
                  inlineData: { 
                    mimeType: mimeType, 
                    data: audioBase64 
                  } 
                }
              ]
            }
          ]
        });
        
        return result.response.text();
      } catch (modelError) {
        console.error("Erro com modelo de √°udio experimental:", modelError);
        
        // Fallback para texto se falhar
        // Enviar mensagem gen√©rica ao usu√°rio
        return "N√£o foi poss√≠vel transcrever o √°udio. Por favor, digite seu texto ou tente novamente mais tarde.";
      }
    } catch (error: any) {
      console.error("Erro ao processar √°udio:", error);
      // Retornar mensagem amig√°vel em vez de lan√ßar erro
      return "Ocorreu um erro ao processar o √°udio. Por favor, digite sua mensagem.";
    }
    */
  }
  
  /**
   * Detecta inten√ß√µes no texto transcrito
   * @param transcribedText Texto transcrito do √°udio
   * @returns Objeto com inten√ß√µes detectadas
   */
  async detectIntent(transcribedText: string): Promise<any> {
    try {
      const result = await this.geminiService['defaultModel'].generateContent({
        contents: [
          {
            role: 'user',
            parts: [{ 
              text: `Identifique as inten√ß√µes do usu√°rio nesta mensagem e extraia 
              informa√ß√µes estruturadas. Se houver men√ß√£o a reservas, check-in, check-out, 
              propriedades, datas ou informa√ß√µes de contato, extraia esses dados.
              
              Retorne um objeto JSON com:
              - intent: a inten√ß√£o principal (reservation, query, information, etc)
              - entities: entidades extra√≠das (datas, locais, pessoas, valores)
              - confidence: n√≠vel de confian√ßa na detec√ß√£o (0.0 a 1.0)
              
              Texto: ${transcribedText}`
            }]
          }
        ],
        generationConfig: {
          temperature: 0.1,
        }
      });
      
      const content = result.response.text();
      
      try {
        const jsonMatch = content.match(/\{[\s\S]*\}/);
        const jsonString = jsonMatch ? jsonMatch[0] : content;
        return JSON.parse(jsonString);
      } catch (jsonError) {
        console.error("Erro ao analisar JSON da resposta de inten√ß√£o:", jsonError);
        return { 
          intent: "unknown",
          entities: [],
          confidence: 0.0,
          rawText: transcribedText
        };
      }
    } catch (error: any) {
      console.error("Erro ao detectar inten√ß√£o:", error);
      return { 
        intent: "error",
        entities: [],
        confidence: 0.0,
        error: error.message,
        rawText: transcribedText
      };
    }
  }
}

export const speechService = SpeechService.getInstance();