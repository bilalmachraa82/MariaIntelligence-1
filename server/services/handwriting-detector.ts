/**
 * Detector simplificado de manuscritos baseado em heur√≠sticas
 * 
 * Vers√£o compat√≠vel com Node.js que n√£o depende de APIs espec√≠ficas do navegador
 * como DOMMatrix, que n√£o est√° dispon√≠vel no ambiente Node.js padr√£o.
 */

import * as fs from 'fs';
import * as path from 'path';

export class HandwritingDetector {
  /**
   * Analisa um PDF para detectar se cont√©m manuscritos
   * @param pdfBuffer Buffer do PDF a ser analisado
   * @returns Pontua√ß√£o entre 0 e 1 (0 = sem manuscritos, 1 = provavelmente manuscrito)
   */
  public async analyzePdf(pdfBuffer: Buffer): Promise<number> {
    try {
      // Abordagem alternativa: an√°lise baseada em texto extra√≠do por outros meios
      // Esta vers√£o n√£o usa pdfjs diretamente para evitar problemas de compatibilidade com Node.js
      
      // Extrair conte√∫do como texto simples
      // Usaremos uma heur√≠stica baseada apenas no conte√∫do textual
      const text = pdfBuffer.toString('utf-8', 0, Math.min(10000, pdfBuffer.length));
      
      // Aplicar heur√≠sticas para detectar manuscritos
      const score = this.analyzeTextContent(text);
      
      console.log(`üìù An√°lise de manuscrito: pontua√ß√£o ${score.toFixed(2)}`);
      
      return score;
    } catch (error) {
      console.error('‚ùå Erro ao analisar PDF para detec√ß√£o de manuscritos:', error);
      return 0; // Por seguran√ßa, assumir que n√£o √© manuscrito em caso de erro
    }
  }
  
  /**
   * Analisa o conte√∫do textual para detectar caracter√≠sticas de manuscritos
   * @param text Texto extra√≠do do PDF
   * @returns Pontua√ß√£o entre 0 e 1
   */
  private analyzeTextContent(text: string): number {
    // Implementa√ß√£o simplificada baseada apenas no texto
    
    // 1. Verificar densidade de texto (menos texto = mais chance de ser manuscrito)
    const contentLength = text.length;
    // Para texto extra√≠do, manuscritos tendem a ter menos conte√∫do leg√≠vel
    const densityScore = Math.max(0, Math.min(1, 1 - (contentLength / 5000)));
    
    // 2. Verificar propor√ß√£o de caracteres n√£o-alfanum√©ricos (manuscritos tendem a ter mais ru√≠do na extra√ß√£o)
    const nonAlphanumericCount = (text.match(/[^a-zA-Z0-9\s]/g) || []).length;
    const nonAlphanumericRatio = nonAlphanumericCount / Math.max(1, contentLength);
    const noiseScore = Math.min(1, nonAlphanumericRatio * 5); // Normalizar

    // 3. Verificar padr√µes de formata√ß√£o t√≠picos de documentos digitais
    const hasFormattedParagraphs = /\n\s*\n/.test(text);
    const hasNumberedLists = /\n\s*\d+\.\s/.test(text);
    const hasTabularData = /\n\s*\|/.test(text) || /\t/.test(text);
    const formattingScore = (hasFormattedParagraphs || hasNumberedLists || hasTabularData) ? 0 : 0.5;
    
    // 4. Verificar caracteres t√≠picos de documentos digitalizados mas raros em manuscritos
    const digitizedPatterns = /[¬©¬Æ‚Ñ¢¬ß¬∂‚Ä†‚Ä°]/g;
    const hasDigitizedPatterns = digitizedPatterns.test(text) ? 0 : 0.3;
    
    // 5. An√°lise estat√≠stica de comprimento de palavras (manuscritos tendem a ter mais varia√ß√£o)
    const words = text.match(/\b\w+\b/g) || [];
    const wordLengths = words.map(w => w.length);
    const averageWordLength = wordLengths.reduce((sum, len) => sum + len, 0) / Math.max(1, wordLengths.length);
    
    // Calcular vari√¢ncia nos comprimentos das palavras
    let variance = 0;
    if (wordLengths.length > 0) {
      variance = wordLengths.reduce((sum, len) => sum + Math.pow(len - averageWordLength, 2), 0) / wordLengths.length;
    }
    // Manuscritos tendem a ter mais varia√ß√£o na extra√ß√£o de texto
    const varianceScore = Math.min(1, variance / 10);
    
    // Calcular pontua√ß√£o final (ponderada)
    const finalScore = (
      (densityScore * 0.3) + 
      (noiseScore * 0.2) + 
      (formattingScore * 0.2) + 
      (hasDigitizedPatterns * 0.1) + 
      (varianceScore * 0.2)
    );
    
    return finalScore;
  }
}

export default HandwritingDetector;