/**\n * Performance Monitoring Middleware for MariaIntelligence\n * Tracks and analyzes application performance metrics\n */\n\nimport { Request, Response, NextFunction } from 'express';\nimport Redis from 'ioredis';\nimport fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport process from 'process';\n\ninterface PerformanceMetrics {\n  timestamp: number;\n  method: string;\n  path: string;\n  statusCode: number;\n  responseTime: number;\n  memoryUsage: NodeJS.MemoryUsage;\n  cpuUsage: NodeJS.CpuUsage;\n  activeConnections: number;\n}\n\ninterface SystemMetrics {\n  timestamp: number;\n  cpu: {\n    usage: number;\n    loadAverage: number[];\n  };\n  memory: {\n    usage: number;\n    free: number;\n    total: number;\n    heapUsed: number;\n    heapTotal: number;\n  };\n  disk: {\n    usage?: number;\n  };\n  network: {\n    connections: number;\n  };\n}\n\nclass PerformanceMonitor {\n  private redis?: Redis;\n  private metricsBuffer: PerformanceMetrics[] = [];\n  private systemMetricsBuffer: SystemMetrics[] = [];\n  private startTime = Date.now();\n  private requestCount = 0;\n  private errorCount = 0;\n  private bufferSize = 1000;\n  private flushInterval = 30000; // 30 seconds\n  private monitoringInterval?: NodeJS.Timeout;\n  private initialCpuUsage = process.cpuUsage();\n\n  constructor(redisConfig?: any) {\n    if (redisConfig) {\n      try {\n        this.redis = new Redis(redisConfig);\n        console.log('ðŸ“Š Performance monitor connected to Redis');\n      } catch (error) {\n        console.warn('âš ï¸  Redis not available for performance monitoring:', error);\n      }\n    }\n\n    // Start system monitoring\n    this.startSystemMonitoring();\n    \n    // Flush metrics periodically\n    this.startMetricsFlush();\n\n    // Graceful shutdown\n    process.on('SIGTERM', () => this.shutdown());\n    process.on('SIGINT', () => this.shutdown());\n  }\n\n  /**\n   * Express middleware for performance monitoring\n   */\n  middleware() {\n    return (req: Request, res: Response, next: NextFunction) => {\n      const startTime = Date.now();\n      const startCpuUsage = process.cpuUsage();\n      const startMemoryUsage = process.memoryUsage();\n\n      // Override res.end to capture metrics\n      const originalEnd = res.end;\n      res.end = function(this: Response, ...args: any[]) {\n        const endTime = Date.now();\n        const responseTime = endTime - startTime;\n        const endCpuUsage = process.cpuUsage(startCpuUsage);\n        const endMemoryUsage = process.memoryUsage();\n\n        // Record metrics\n        const metrics: PerformanceMetrics = {\n          timestamp: endTime,\n          method: req.method,\n          path: req.path,\n          statusCode: res.statusCode,\n          responseTime,\n          memoryUsage: endMemoryUsage,\n          cpuUsage: endCpuUsage,\n          activeConnections: res.socket?.server?.connections || 0\n        };\n\n        // Add to monitoring\n        (req as any).performanceMonitor?.recordMetrics(metrics);\n\n        return originalEnd.apply(this, args);\n      };\n\n      // Store reference for recording\n      (req as any).performanceMonitor = this;\n      next();\n    };\n  }\n\n  /**\n   * Record performance metrics\n   */\n  recordMetrics(metrics: PerformanceMetrics) {\n    this.requestCount++;\n    \n    if (metrics.statusCode >= 400) {\n      this.errorCount++;\n    }\n\n    // Add to buffer\n    this.metricsBuffer.push(metrics);\n\n    // Flush buffer if full\n    if (this.metricsBuffer.length >= this.bufferSize) {\n      this.flushMetrics();\n    }\n\n    // Log slow requests\n    if (metrics.responseTime > 1000) {\n      console.warn(`ðŸŒ Slow request detected: ${metrics.method} ${metrics.path} - ${metrics.responseTime}ms`);\n    }\n\n    // Log high memory usage\n    if (metrics.memoryUsage.heapUsed > 400 * 1024 * 1024) { // 400MB\n      console.warn(`ðŸ§  High memory usage detected: ${Math.round(metrics.memoryUsage.heapUsed / 1024 / 1024)}MB`);\n    }\n  }\n\n  /**\n   * Start system monitoring\n   */\n  private startSystemMonitoring() {\n    this.monitoringInterval = setInterval(() => {\n      const cpuUsage = process.cpuUsage(this.initialCpuUsage);\n      const memoryUsage = process.memoryUsage();\n      const loadAverage = os.loadavg();\n      const freeMemory = os.freemem();\n      const totalMemory = os.totalmem();\n\n      const systemMetrics: SystemMetrics = {\n        timestamp: Date.now(),\n        cpu: {\n          usage: (cpuUsage.user + cpuUsage.system) / 1000000, // Convert to seconds\n          loadAverage\n        },\n        memory: {\n          usage: ((totalMemory - freeMemory) / totalMemory) * 100,\n          free: freeMemory,\n          total: totalMemory,\n          heapUsed: memoryUsage.heapUsed,\n          heapTotal: memoryUsage.heapTotal\n        },\n        disk: {},\n        network: {\n          connections: this.requestCount\n        }\n      };\n\n      this.systemMetricsBuffer.push(systemMetrics);\n\n      // Check thresholds\n      this.checkThresholds(systemMetrics);\n\n    }, 30000); // Every 30 seconds\n  }\n\n  /**\n   * Check performance thresholds and alert\n   */\n  private checkThresholds(metrics: SystemMetrics) {\n    // CPU usage alert (> 80%)\n    if (metrics.cpu.loadAverage[0] > 0.8 * os.cpus().length) {\n      console.warn(`âš¡ High CPU load detected: ${metrics.cpu.loadAverage[0].toFixed(2)}`);\n    }\n\n    // Memory usage alert (> 85%)\n    if (metrics.memory.usage > 85) {\n      console.warn(`ðŸ§  High memory usage detected: ${metrics.memory.usage.toFixed(1)}%`);\n    }\n\n    // Error rate alert (> 5%)\n    const errorRate = (this.errorCount / this.requestCount) * 100;\n    if (errorRate > 5 && this.requestCount > 10) {\n      console.warn(`ðŸš¨ High error rate detected: ${errorRate.toFixed(1)}%`);\n    }\n  }\n\n  /**\n   * Start periodic metrics flushing\n   */\n  private startMetricsFlush() {\n    setInterval(() => {\n      this.flushMetrics();\n      this.flushSystemMetrics();\n    }, this.flushInterval);\n  }\n\n  /**\n   * Flush metrics to storage\n   */\n  private async flushMetrics() {\n    if (this.metricsBuffer.length === 0) return;\n\n    const metrics = [...this.metricsBuffer];\n    this.metricsBuffer = [];\n\n    try {\n      // Store in Redis if available\n      if (this.redis) {\n        const key = `performance:metrics:${Date.now()}`;\n        await this.redis.setex(key, 3600, JSON.stringify(metrics)); // 1 hour TTL\n      }\n\n      // Also store in local file for persistence\n      const logDir = path.join(process.cwd(), 'logs');\n      if (!fs.existsSync(logDir)) {\n        fs.mkdirSync(logDir, { recursive: true });\n      }\n\n      const logFile = path.join(logDir, `performance-${new Date().toISOString().split('T')[0]}.json`);\n      const logData = {\n        timestamp: Date.now(),\n        metrics,\n        summary: this.generateSummary(metrics)\n      };\n\n      fs.appendFileSync(logFile, JSON.stringify(logData) + '\\n');\n\n    } catch (error) {\n      console.error('Failed to flush performance metrics:', error);\n    }\n  }\n\n  /**\n   * Flush system metrics to storage\n   */\n  private async flushSystemMetrics() {\n    if (this.systemMetricsBuffer.length === 0) return;\n\n    const metrics = [...this.systemMetricsBuffer];\n    this.systemMetricsBuffer = [];\n\n    try {\n      // Store in Redis if available\n      if (this.redis) {\n        const key = `performance:system:${Date.now()}`;\n        await this.redis.setex(key, 3600, JSON.stringify(metrics)); // 1 hour TTL\n      }\n\n      // Store summary in file\n      const logDir = path.join(process.cwd(), 'logs');\n      const logFile = path.join(logDir, `system-metrics-${new Date().toISOString().split('T')[0]}.json`);\n      \n      const summary = {\n        timestamp: Date.now(),\n        averageCpu: metrics.reduce((sum, m) => sum + m.cpu.loadAverage[0], 0) / metrics.length,\n        averageMemory: metrics.reduce((sum, m) => sum + m.memory.usage, 0) / metrics.length,\n        peakMemory: Math.max(...metrics.map(m => m.memory.usage)),\n        samples: metrics.length\n      };\n\n      fs.appendFileSync(logFile, JSON.stringify(summary) + '\\n');\n\n    } catch (error) {\n      console.error('Failed to flush system metrics:', error);\n    }\n  }\n\n  /**\n   * Generate performance summary\n   */\n  private generateSummary(metrics: PerformanceMetrics[]) {\n    const responseTimes = metrics.map(m => m.responseTime);\n    const statusCodes = metrics.map(m => m.statusCode);\n\n    return {\n      totalRequests: metrics.length,\n      averageResponseTime: responseTimes.reduce((sum, time) => sum + time, 0) / responseTimes.length,\n      minResponseTime: Math.min(...responseTimes),\n      maxResponseTime: Math.max(...responseTimes),\n      p95ResponseTime: this.percentile(responseTimes, 0.95),\n      p99ResponseTime: this.percentile(responseTimes, 0.99),\n      errorRate: (statusCodes.filter(code => code >= 400).length / statusCodes.length) * 100,\n      throughput: metrics.length / 30 // requests per second (30 second window)\n    };\n  }\n\n  /**\n   * Calculate percentile\n   */\n  private percentile(values: number[], p: number): number {\n    const sorted = values.sort((a, b) => a - b);\n    const index = Math.ceil(sorted.length * p) - 1;\n    return sorted[index] || 0;\n  }\n\n  /**\n   * Get current performance stats\n   */\n  async getStats() {\n    const uptime = Date.now() - this.startTime;\n    const memoryUsage = process.memoryUsage();\n    const cpuUsage = process.cpuUsage(this.initialCpuUsage);\n    \n    return {\n      uptime,\n      requestCount: this.requestCount,\n      errorCount: this.errorCount,\n      errorRate: (this.errorCount / this.requestCount) * 100,\n      memoryUsage: {\n        heapUsed: Math.round(memoryUsage.heapUsed / 1024 / 1024), // MB\n        heapTotal: Math.round(memoryUsage.heapTotal / 1024 / 1024), // MB\n        external: Math.round(memoryUsage.external / 1024 / 1024) // MB\n      },\n      cpuUsage: {\n        user: cpuUsage.user / 1000000, // seconds\n        system: cpuUsage.system / 1000000 // seconds\n      },\n      systemLoad: os.loadavg(),\n      freeMemory: Math.round(os.freemem() / 1024 / 1024), // MB\n      totalMemory: Math.round(os.totalmem() / 1024 / 1024) // MB\n    };\n  }\n\n  /**\n   * Get performance dashboard data\n   */\n  async getDashboardData() {\n    try {\n      const stats = await this.getStats();\n      const recentMetrics = this.metricsBuffer.slice(-100); // Last 100 requests\n      \n      return {\n        stats,\n        recentMetrics: recentMetrics.map(m => ({\n          timestamp: m.timestamp,\n          method: m.method,\n          path: m.path,\n          responseTime: m.responseTime,\n          statusCode: m.statusCode\n        })),\n        summary: recentMetrics.length > 0 ? this.generateSummary(recentMetrics) : null\n      };\n    } catch (error) {\n      console.error('Failed to get dashboard data:', error);\n      return null;\n    }\n  }\n\n  /**\n   * Graceful shutdown\n   */\n  async shutdown() {\n    console.log('ðŸ“Š Shutting down performance monitor...');\n    \n    if (this.monitoringInterval) {\n      clearInterval(this.monitoringInterval);\n    }\n\n    // Flush remaining metrics\n    await this.flushMetrics();\n    await this.flushSystemMetrics();\n\n    if (this.redis) {\n      this.redis.disconnect();\n    }\n\n    console.log('ðŸ“Š Performance monitor shutdown complete');\n  }\n}\n\n// Export singleton instance\nconst performanceConfig = require('../../config/performance.config.js');\nconst performanceMonitor = new PerformanceMonitor(performanceConfig.redis);\n\nexport default performanceMonitor;\nexport { PerformanceMonitor, PerformanceMetrics, SystemMetrics };\n"